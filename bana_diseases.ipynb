{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T07:54:56.652367300Z",
     "start_time": "2023-11-09T07:54:34.562819Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/repodata.json HTTP/1.1\" 304 0\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - torch\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install --name bananavision --file requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85bdd579202a408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T07:14:47.962739900Z",
     "start_time": "2023-11-09T07:14:35.524399800Z"
    }
   },
   "outputs": [],
   "source": [
    "!setup_environment.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a380d9991b7fa9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T07:51:01.807931400Z",
     "start_time": "2023-11-09T07:51:01.788910800Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m shuffle\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33902b1cd94913e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T19:07:35.920704200Z",
     "start_time": "2023-11-08T19:07:35.894316700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_dataframe_from_images(folders):\n",
    "    \"\"\"\n",
    "    Create a DataFrame by reading images from multiple folders and labeling them with the folder names.\n",
    "\n",
    "    Args:\n",
    "        folders (list): List of folder paths to read images from.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing image paths and labels.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for folder in folders:\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                image_path = os.path.join(folder, filename)\n",
    "                label = os.path.basename(folder)\n",
    "                data.append((image_path, label))\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['image_path', 'label'])\n",
    "    df = shuffle(df)\n",
    "    return df\n",
    "\n",
    "def preprocess_images(df, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess the images in the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing image paths and labels.\n",
    "        target_size (tuple): Target spatial size for resizing. Defaults to (224, 224).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the preprocessed images and corresponding one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(target_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image_path, label in df.values:\n",
    "        image = Image.open(image_path)\n",
    "        image = transform(image)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    encoded_labels = onehot_encode_labels(np.array(labels).reshape(-1, 1))  # One-hot encode labels\n",
    "\n",
    "    return images, encoded_labels\n",
    "\n",
    "\n",
    "def onehot_encode_labels(labels):\n",
    "    \"\"\"\n",
    "    One-hot encode the labels in the list.\n",
    "\n",
    "    Args:\n",
    "        labels (list): List of labels.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: One-hot encoded labels.\n",
    "    \"\"\"\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoded_labels = encoder.fit_transform(labels).toarray()\n",
    "    return torch.tensor(encoded_labels)\n",
    "def train_model(images, labels, num_epochs=50, batch_size=16, num_classes=3):\n",
    "    \"\"\"\n",
    "    Train the ResNet-152 model on the given images and labels.\n",
    "\n",
    "    Args:\n",
    "        images (list of torch.Tensor): List of preprocessed images.\n",
    "        labels (list of torch.Tensor): List of one-hot encoded labels.\n",
    "        num_epochs (int, optional): Number of training epochs. Defaults to 10.\n",
    "        batch_size (int, optional): Batch size for training. Defaults to 16.\n",
    "        num_classes (int, optional): Number of classes\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: Trained ResNet-152 model.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet152()  # Use ResNet-152\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)  # Customize the last fully connected layer\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Convert lists of tensors to single tensors\n",
    "    images_tensor = torch.stack(images)\n",
    "    labels_tensor = torch.stack(tuple(labels))\n",
    "\n",
    "    # Create a TensorDataset from the tensors\n",
    "    train_dataset = torch.utils.data.TensorDataset(images_tensor, labels_tensor)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Print loss every 100 batches\n",
    "            if i % 100 == 99:\n",
    "                print(f\"Epoch: {epoch + 1}/{num_epochs}, Batch: {i + 1}, Loss: {running_loss / 100}\")\n",
    "                running_loss = 0.0\n",
    "                sys.stdout.flush()  # Force the output to be displayed\n",
    "\n",
    "        # Print loss at the end of each epoch\n",
    "        print(f\"Epoch: {epoch + 1}/{num_epochs}, Final Loss: {running_loss / len(train_loader)}\")\n",
    "        sys.stdout.flush()\n",
    "    return model\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Convert one-hot encoded labels to class indices\n",
    "            _, labels = torch.max(labels, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return val_loss, accuracy\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2d0c8d9a9fd7d6e"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9138c7f2471afc05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T19:07:39.392962900Z",
     "start_time": "2023-11-08T19:07:39.304236700Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shuffle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Create a DataFrame from the images in the training and validation folders\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m df_train \u001B[38;5;241m=\u001B[39m create_dataframe_from_images([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/train/BLACK SIGATOKA_1\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/train/FUSARIUM WILT_1\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/train/HEALTHY_1\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      3\u001B[0m df_validation \u001B[38;5;241m=\u001B[39m create_dataframe_from_images([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/test/BLACK SIGATOKA_2\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/test/FUSARIUM WILT_2\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/test/HEALTHY_2\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "Cell \u001B[1;32mIn[11], line 20\u001B[0m, in \u001B[0;36mcreate_dataframe_from_images\u001B[1;34m(folders)\u001B[0m\n\u001B[0;32m     17\u001B[0m             data\u001B[38;5;241m.\u001B[39mappend((image_path, label))\n\u001B[0;32m     19\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(data, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage_path\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 20\u001B[0m df \u001B[38;5;241m=\u001B[39m shuffle(df)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "\u001B[1;31mNameError\u001B[0m: name 'shuffle' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the images in the training and validation folders\n",
    "df_train = create_dataframe_from_images(['data/train/BLACK SIGATOKA_1', 'data/train/FUSARIUM WILT_1','data/train/HEALTHY_1'])\n",
    "df_validation = create_dataframe_from_images(['data/test/BLACK SIGATOKA_2', 'data/test/FUSARIUM WILT_2','data/test/HEALTHY_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df_train.head())\n",
    "display(df_train.shape)\n",
    "display(df_validation.head())\n",
    "display(df_validation.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b80faf8a6d75fb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess the images\n",
    "train_images,train_labels = preprocess_images(df_train)\n",
    "test_images,test_labels = preprocess_images(df_validation)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc78bdf70ec7788b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define your validation DataLoader, criterion, and device\n",
    "# Convert lists of tensors to single tensors\n",
    "images_tensor = torch.stack(test_images)\n",
    "labels_tensor = torch.stack(tuple(test_labels))\n",
    "val_dataset = torch.utils.data.TensorDataset(images_tensor, labels_tensor)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "criterion = nn.CrossEntropyLoss()  # Use an appropriate criterion for your task\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model\n",
    "trained_model = train_model(train_images, train_labels)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c27714c41b07375"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6cbc1df53ea877c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T19:01:55.050312100Z",
     "start_time": "2023-11-08T19:01:54.942293500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train/BLACK SIGATOKA_1\\Image_870.jpg</td>\n",
       "      <td>BLACK SIGATOKA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train/BLACK SIGATOKA_1\\Image_871.jpg</td>\n",
       "      <td>BLACK SIGATOKA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train/BLACK SIGATOKA_1\\Image_872.jpg</td>\n",
       "      <td>BLACK SIGATOKA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train/BLACK SIGATOKA_1\\Image_873.jpg</td>\n",
       "      <td>BLACK SIGATOKA_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train/BLACK SIGATOKA_1\\Image_874.jpg</td>\n",
       "      <td>BLACK SIGATOKA_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image_path             label\n",
       "0  data/train/BLACK SIGATOKA_1\\Image_870.jpg  BLACK SIGATOKA_1\n",
       "1  data/train/BLACK SIGATOKA_1\\Image_871.jpg  BLACK SIGATOKA_1\n",
       "2  data/train/BLACK SIGATOKA_1\\Image_872.jpg  BLACK SIGATOKA_1\n",
       "3  data/train/BLACK SIGATOKA_1\\Image_873.jpg  BLACK SIGATOKA_1\n",
       "4  data/train/BLACK SIGATOKA_1\\Image_874.jpg  BLACK SIGATOKA_1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validate the trained model\n",
    "val_loss, val_accuracy = validate_model(trained_model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtransforms\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_single_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    return image\n",
    "\n",
    "def predict_and_display_image(model, image_path, label_names, device):\n",
    "    model.eval()\n",
    "    image = preprocess_single_image(image_path)\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)[0]  # Assuming batch size is 1\n",
    "    predicted_prob, predicted_class = torch.max(probabilities, 0)\n",
    "    predicted_label = label_names[predicted_class.item()]\n",
    "\n",
    "    # Display the image\n",
    "    image = Image.open(image_path)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted Label: {predicted_label}, Probability: {predicted_prob.item():.2%}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "image_path_to_test = 'data/test/HEALTHY_2/Image_5904.jpg'\n",
    "label_names = ['BLACK SIGATOKA', 'FUSARIUM WILT', 'HEALTHY']\n",
    "predict_and_display_image(trained_model, image_path_to_test, label_names, device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T11:36:11.311493100Z",
     "start_time": "2023-11-09T11:36:11.085772200Z"
    }
   },
   "id": "33e8c0cf883ca4a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
